# 本地運行中文大型語言模型：llama 和 Alpaca 使用指南 📘

近幾個月來，大型語言模型（LLMs）在全球開發者社群中引起了廣泛的關注和興趣，尤其是在聊天機器人、個人助理和內容創建的領域。這些模型，通過其驚人的語言理解和生成能力，為我們展現了一個充滿無限可能性的未來，激發了開發者、AI 和 NLP 社區的熱情和創新。

LLMs 是一種能夠生成與人類語言相似文本並自然理解語言提示的機器學習模型。它們通過大量的文本數據（如書籍、文章、網站等）訓練，學會預測在給定輸入之後最可能出現的單詞或短語。LLMs 不僅能夠結合特定領域的數據有效解答查詢，而且在處理模型初步訓練期間無法接觸的信息（例如公司的內部文檔或知識庫）時也顯得尤為有用。
歡迎探索 [llama.cpp](https://github.com/ggerganov/llama.cpp)！這個C++庫將指引您，不依靠外部雲服務，在自己的本地機器上運行中文大型語言模型——llama 和 Alpaca。

# 🚀 在 llama.cpp 中實現 LLMs 的本地運行

llama.cpp 是一個C++庫，專為在不依賴外部雲服務的情況下，在您自己的本地機器上運行中文大型語言模型——llama 和 Alpaca 而設計。通過這個項目，我們致力於提供一個平台，讓開發者能夠輕鬆地在自己的系統上運行和利用大型語言模型的威力，開創更多的可能性和應用場景。

## 快速入門

這個快速入門指南將引導您在配備Intel CPU的Windows系統上安裝和配置llama.cpp。我們將帶領您從編譯器的安裝到模型的運行，讓您完全感受到llama和Alpaca這兩種中文大語言模型的魅力。

- [前往Windows Intel CPU安裝和配置指南](./Windows_Installation/Guide.md)

# 🌱 未來規劃

- 探索並提供對其他加速計算庫的支持和搭建指南。
- 預計將添加對M系列晶片的macOS的安裝教學。

感謝您閱讀，願您的編碼之旅一帆風順！
